# NeurIPS

## Quantization
- BinGAN: Learning Compact Binary Descriptors with a Regularized GAN
- HitNet: Hybrid Ternary Recurrent Neural Network

## Pruning
- Frequency-Domain Dynamic Pruning for Convolutional Neural Networks
- Discrimination-aware Channel Pruning for Deep Neural Networks
- ChannelNets: Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions

## Distillation
- Paraphrasing Complex Network: Network Compression via Factor Transfer

# CVPR

## Quantization
- Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference
- SYQ: Learning Symmetric Quantization for Efficient Deep Neural Networks
- Two-Step Quantization for Low-Bit Neural Networks
- CLIP-Q: Deep Network Compression Learning by In-Parallel Pruning-Quantization
- Quantization of Fully Convolutional Networks for Accurate Biomedical Image Segmentation
- Explicit Loss-Error-Aware Quantization for Low-Bit Deep Neural Networks

## Pruning
- PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning
- "Learning-Compression" Algorithms for Neural Net Pruning
- NISP: Pruning Networks Using Neuron Importance Score Propagation
- Learning Compact Recurrent Neural Networks With Block-Term Tensor Decomposition